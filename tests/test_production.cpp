#include "catch.hpp"
#include "CHTL/CHTLLexer/Lexer.h"
#include "CHTL/CHTLParser/Parser.h"
#include "CHTL/CHTLGenerator/Generator.h"
#include "CHTL/CHTLCommon/CompilerError.h"
#include "CHTL/CHTLCommon/CompilerConfig.h"
#include "CHTL/CHTLCommon/Validation.h"
#include <string>
#include <chrono>

using namespace CHTL;

TEST_CASE("Production - è¾¹ç•Œæƒ…å†µæµ‹è¯•", "[production][boundary]") {
    SECTION("ç©ºè¾“å…¥") {
        std::string source = "";
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        
        REQUIRE(tokens.size() == 1);  // åªæœ‰ EOF
        REQUIRE(tokens[0].type == TokenType::END_OF_FILE);
    }
    
    SECTION("åªæœ‰ç©ºç™½ç¬¦") {
        std::string source = "   \n\t\r\n   ";
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        
        // ç©ºç™½ç¬¦åº”è¯¥è¢«è·³è¿‡ï¼Œä½†æŸäº›å®ç°å¯èƒ½ä¼šè®°å½•å®ƒä»¬
        // è‡³å°‘åº”è¯¥æœ‰ EOF
        REQUIRE(tokens.size() >= 1);
        REQUIRE(tokens.back().type == TokenType::END_OF_FILE);
    }
    
    SECTION("åªæœ‰æ³¨é‡Š") {
        std::string source = "// æ³¨é‡Š\n/* å¤šè¡Œæ³¨é‡Š */\n# ç”Ÿæˆå™¨æ³¨é‡Š";
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        
        // æ³¨é‡Šä¼šè¢«è·³è¿‡ï¼Œåªç•™ä¸‹ EOF
        // ä½†å¦‚æœæ³¨é‡Šè¢«è®°å½•ä¸º tokenï¼Œå¯èƒ½ä¼šæœ‰å¤šä¸ª
        REQUIRE(tokens.size() <= 2);  // EOF å’Œå¯èƒ½çš„æ³¨é‡Š token
        REQUIRE(tokens.back().type == TokenType::END_OF_FILE);
    }
    
    SECTION("éå¸¸é•¿çš„æ ‡è¯†ç¬¦") {
        std::string longId(255, 'a');  // æœ€å¤§é•¿åº¦
        std::string source = longId + " { }";
        
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        Parser parser(std::move(tokens));
        auto ast = parser.parse();
        
        REQUIRE(ast.size() == 1);
    }
}

TEST_CASE("Production - æ·±åº¦åµŒå¥—æµ‹è¯•", "[production][nesting]") {
    SECTION("é€‚åº¦åµŒå¥—ï¼ˆ50å±‚ï¼‰") {
        std::string source;
        for (int i = 0; i < 50; ++i) {
            source += "div { ";
        }
        for (int i = 0; i < 50; ++i) {
            source += " }";
        }
        
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        Parser parser(std::move(tokens));
        auto ast = parser.parse();
        
        REQUIRE(ast.size() == 1);
    }
    
    SECTION("æ·±åº¦åµŒå¥—æ£€æµ‹ï¼ˆè¶…è¿‡é™åˆ¶ï¼‰") {
        std::string source;
        // åˆ›å»ºè¶…è¿‡é™åˆ¶çš„åµŒå¥—ï¼ˆMAX_NESTING_DEPTH + 10ï¼‰
        size_t depth = CompilerConfig::MAX_NESTING_DEPTH + 10;
        for (size_t i = 0; i < depth; ++i) {
            source += "div { ";
        }
        for (size_t i = 0; i < depth; ++i) {
            source += " }";
        }
        
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        Parser parser(std::move(tokens));
        
        // åº”è¯¥åœ¨è§£ææ—¶æ£€æµ‹åˆ°æ·±åº¦é™åˆ¶
        bool threw_correct_exception = false;
        try {
            parser.parse();
        } catch (const ResourceLimitError&) {
            threw_correct_exception = true;
        } catch (...) {
            // å…¶ä»–å¼‚å¸¸
        }
        
        REQUIRE(threw_correct_exception);
    }
}

TEST_CASE("Production - å­—ç¬¦ä¸²å¤„ç†", "[production][strings]") {
    SECTION("åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„å­—ç¬¦ä¸²") {
        std::string source = R"(div { text: "Hello\nWorld\t\"Test\""; })";
        
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        Parser parser(std::move(tokens));
        auto ast = parser.parse();
        
        REQUIRE(ast.size() == 1);
        
        auto* elem = dynamic_cast<ElementNode*>(ast[0].get());
        REQUIRE(elem != nullptr);
        auto attrs = elem->getAttributes();
        // Lexer å·²ç»å¤„ç†äº†è½¬ä¹‰ï¼Œæ‰€ä»¥å­˜å‚¨çš„æ˜¯å®é™…å­—ç¬¦
        std::string expected = "Hello\nWorld\t\"Test\"";
        REQUIRE(attrs["text"] == expected);
    }
    
    SECTION("åŒ…å« Unicode çš„å­—ç¬¦ä¸²") {
        std::string source = R"(div { text: "ä½ å¥½ä¸–ç•Œ ğŸ‰"; })";
        
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        Parser parser(std::move(tokens));
        auto ast = parser.parse();
        
        REQUIRE(ast.size() == 1);
    }
    
    SECTION("ç©ºå­—ç¬¦ä¸²") {
        std::string source = R"(div { text: ""; })";
        
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        Parser parser(std::move(tokens));
        auto ast = parser.parse();
        
        REQUIRE(ast.size() == 1);
    }
    
    SECTION("æœªé—­åˆçš„å­—ç¬¦ä¸²åº”è¯¥æŠ›å‡ºå¼‚å¸¸") {
        std::string source = R"(div { text: "unclosed)";
        
        Lexer lexer(source);
        
        // åº”è¯¥åœ¨ tokenize æ—¶æŠ›å‡ºå¼‚å¸¸
        bool threw_exception = false;
        try {
            lexer.tokenize();
        } catch (const LexerError&) {
            threw_exception = true;
        } catch (const std::exception& e) {
            INFO("æŠ›å‡ºäº†å…¶ä»–å¼‚å¸¸: " << e.what());
        }
        
        REQUIRE(threw_exception);
    }
}

TEST_CASE("Production - HTML è½¬ä¹‰æµ‹è¯•", "[production][escaping]") {
    SECTION("HTML ç‰¹æ®Šå­—ç¬¦è½¬ä¹‰") {
        std::string source = R"(div { text: "<script>alert('xss')</script>"; })";
        
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        Parser parser(std::move(tokens));
        auto ast = parser.parse();
        
        Generator generator;
        std::string html = generator.generate(ast);
        
        // ç¡®ä¿ < å’Œ > è¢«è½¬ä¹‰
        REQUIRE(html.find("&lt;script&gt;") != std::string::npos);
        REQUIRE(html.find("&lt;/script&gt;") != std::string::npos);
        REQUIRE(html.find("&#39;") != std::string::npos);
    }
    
    SECTION("æ‰€æœ‰ HTML ç‰¹æ®Šå­—ç¬¦") {
        std::string source = R"(div { text: "< > & \" '"; })";
        
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        Parser parser(std::move(tokens));
        auto ast = parser.parse();
        
        Generator generator;
        std::string html = generator.generate(ast);
        
        REQUIRE(html.find("&lt;") != std::string::npos);
        REQUIRE(html.find("&gt;") != std::string::npos);
        REQUIRE(html.find("&amp;") != std::string::npos);
        REQUIRE(html.find("&quot;") != std::string::npos);
        REQUIRE(html.find("&#39;") != std::string::npos);
    }
}

TEST_CASE("Production - é”™è¯¯æ¢å¤æµ‹è¯•", "[production][error]") {
    SECTION("è¯­æ³•é”™è¯¯ä¸åº”è¯¥å´©æºƒ") {
        std::string source = R"(
            div { }
            invalid syntax here
            span { }
        )";
        
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        Parser parser(std::move(tokens));
        
        // åº”è¯¥æ•è·é”™è¯¯ä½†ä¸å´©æºƒ
        REQUIRE_NOTHROW(parser.parse());
    }
}

TEST_CASE("Production - æ€§èƒ½åŸºå‡†", "[production][benchmark][!hide]") {
    SECTION("å¤§æ–‡ä»¶ç¼–è¯‘æ€§èƒ½") {
        // åˆ›å»ºä¸€ä¸ªä¸­ç­‰å¤§å°çš„æ–‡æ¡£ï¼ˆ1000 ä¸ªå…ƒç´ ï¼‰
        std::string source;
        source.reserve(50000);
        
        for (int i = 0; i < 1000; ++i) {
            source += "div { class: \"item" + std::to_string(i) + "\"; ";
            source += "text: \"Item " + std::to_string(i) + "\"; } ";
        }
        
        auto start = std::chrono::high_resolution_clock::now();
        
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        Parser parser(std::move(tokens));
        auto ast = parser.parse();
        Generator generator;
        std::string html = generator.generate(ast);
        
        auto end = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
        
        INFO("ç¼–è¯‘æ—¶é—´: " << duration.count() << "ms");
        INFO("Token æ•°é‡: " << tokens.size());
        INFO("AST èŠ‚ç‚¹æ•°: " << ast.size());
        INFO("è¾“å‡ºå¤§å°: " << html.size() << " å­—èŠ‚");
        
        // æ€§èƒ½ç›®æ ‡: 1000 ä¸ªå…ƒç´ åº”è¯¥åœ¨ 100ms å†…å®Œæˆ
        REQUIRE(duration.count() < 1000);  // å®½æ¾çš„é™åˆ¶
        REQUIRE(ast.size() == 1000);
    }
}

TEST_CASE("Production - å†…å­˜å®‰å…¨", "[production][memory]") {
    SECTION("å¤§é‡èŠ‚ç‚¹ä¸åº”è¯¥å†…å­˜æ³„æ¼") {
        for (int iteration = 0; iteration < 10; ++iteration) {
            std::string source;
            for (int i = 0; i < 100; ++i) {
                source += "div { } ";
            }
            
            Lexer lexer(source);
            auto tokens = lexer.tokenize();
            Parser parser(std::move(tokens));
            auto ast = parser.parse();
            Generator generator;
            std::string html = generator.generate(ast);
            
            // AST åº”è¯¥è‡ªåŠ¨é‡Šæ”¾
        }
        
        // å¦‚æœæœ‰å†…å­˜æ³„æ¼ï¼Œå¤šæ¬¡è¿­ä»£ä¼šç§¯ç´¯
        REQUIRE(true);
    }
}

TEST_CASE("Production - è¾“å…¥éªŒè¯", "[production][validation]") {
    SECTION("æ ‡è¯†ç¬¦éªŒè¯ - åˆæ³•") {
        REQUIRE_NOTHROW(Validation::validateIdentifier("validName"));
        REQUIRE_NOTHROW(Validation::validateIdentifier("_private"));
        REQUIRE_NOTHROW(Validation::validateIdentifier("name123"));
        REQUIRE_NOTHROW(Validation::validateIdentifier("kebab-case"));
    }
    
    SECTION("æ ‡è¯†ç¬¦éªŒè¯ - éæ³•") {
        REQUIRE_THROWS_AS(Validation::validateIdentifier(""), CompilerError);
        REQUIRE_THROWS_AS(Validation::validateIdentifier("123start"), CompilerError);
        REQUIRE_THROWS_AS(Validation::validateIdentifier("invalid space"), CompilerError);
    }
    
    SECTION("å­—ç¬¦ä¸²é•¿åº¦éªŒè¯") {
        std::string short_str(100, 'a');
        REQUIRE_NOTHROW(Validation::validateStringLength(short_str, 1000));
        
        std::string long_str(2000, 'a');
        REQUIRE_THROWS_AS(Validation::validateStringLength(long_str, 1000), ResourceLimitError);
    }
}

TEST_CASE("Production - å®Œæ•´ç¼–è¯‘æµç¨‹", "[production][integration]") {
    SECTION("çœŸå®ä¸–ç•Œç¤ºä¾‹ - ç®€å•é¡µé¢") {
        std::string source = R"(
            html {
                head {
                    title: "ç”Ÿäº§æµ‹è¯•é¡µé¢";
                    charset: "UTF-8";
                }
                
                body {
                    id: "app";
                    class: "container";
                    
                    div {
                        class: "header";
                        
                        text {
                            "æ¬¢è¿ä½¿ç”¨ CHTL"
                        }
                    }
                    
                    div {
                        class: "content";
                        
                        span {
                            text: "å†…å®¹åŒºåŸŸ";
                        }
                    }
                    
                    div {
                        class: "footer";
                        text: "ç‰ˆæƒæ‰€æœ‰";
                    }
                }
            }
        )";
        
        // å®Œæ•´ç¼–è¯‘æµç¨‹
        Lexer lexer(source);
        auto tokens = lexer.tokenize();
        
        REQUIRE(tokens.size() > 0);
        
        Parser parser(std::move(tokens));
        auto ast = parser.parse();
        
        REQUIRE(!parser.hasErrors());
        REQUIRE(ast.size() == 1);
        
        GeneratorConfig config;
        config.prettyPrint = true;
        config.includeDoctype = true;
        
        Generator generator(config);
        std::string html = generator.generate(ast);
        
        // éªŒè¯è¾“å‡º
        REQUIRE(!html.empty());
        REQUIRE(html.find("<!DOCTYPE html>") == 0);
        REQUIRE(html.find("<html>") != std::string::npos);
        REQUIRE(html.find("</html>") != std::string::npos);
        REQUIRE(html.find("æ¬¢è¿ä½¿ç”¨ CHTL") != std::string::npos);
    }
}
